#+BEGIN_HTML
---
layout: post
title: 上篇CNN加速的初步结果
---
#+END_HTML
结论是， 加速效果暂时没有达到预期，但是这个需要后续熟悉架构后再调教。
然而， 模型参数真的是降的狠，当然，模型的能力也随着下降。


速度上， 训练了一个小模型，相比原来提升了约20%。同时模型文件大小缩减到了500K，之前的模型大小在27M，相当于减少了98%的参数量。在准确率表现上，当然多了一些误识别，不过考虑到速度和模型参数这两个因素，这点准确率上的下降微不足道。


在以上的基础上，训练了一个可以在512x288分辨率，CPU（i7-6700）上稳定运行8FPS的模型。
效果尚可，不过更多的速度提升还是来自分辨率的下降和输入被换为黑白。这个当然会带来准确率的损失。
#+BEGIN_HTML
<iframe height=498 width=510 src='http://player.youku.com/embed/XMjUzMzM0ODUxMg==' frameborder=0 'allowfullscreen'></iframe>
#+END_HTML


这其实是个很有意思的现象，网络中的参数，到底有多少实质上可以省略？ 一个接近极限的网络会在运行性能上提高多少？ 网络架构的改进对性能的提升？

未来会继续改进这一模型，相信应该会有一定的空间继续提高。另外一个主题则是新的数据集上的训练，公司新版的标注工具的开发一直没有进度，想要的新标准的标注数据一直没法开始标注，还是怀念人少的时候，自己直接花两天撸一个出来就可以，所以要换用其他现有的数据集进行一些之前就计划的试验分析。


现在的blog风格，要小步快进，迭代更新，以克服自己的晚期懒癌。
