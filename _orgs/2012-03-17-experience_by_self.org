#+BEGIN_EXPORT html
---
layout: post
title: 亲身体验
tags: [share, thoughts]
---
#+END_EXPORT

总是面对别人对我们说，应该应该如何，如果不那样，就会如何。就像代码中掺入了太多的if-else，这样的结构总是让人感觉丑陋的。往往，迷惘也就产生于此，因为迷惘不是什么都不知道，也不是什么都知道，恰恰是雾里看花时，迷惘才出现。 

当if-else出现太多时，代码的可读性往往直线下降，因为逻辑关系上的分支太多了，普通人对于任何事情的上下文的记忆都是有限制的，当逻辑分支过多，就会超出人的上限。当快速缓存满了之后，剩下的性能问题就显而易见了。而人还不仅仅是机器，焦虑往往还伴随着思考受限。那么写下来，成为了一个解决方法，或者扩大自己的记忆力，但是，人都是会碰到自己的上限的，写在纸上成为了剩下的选择，就如同对象的序列化。当需要转储内存对象时，序列化总是第一步。那么如何确定序列化格式，让重新载入可以更好、更快，始终是一个重要议题，譬如，各种清单、TODO List、脑图。这些都是为了在不同的应用背景下，可以让其中的内容能够更加快速的载入被人来处理的设计。能够快速载入的标准似乎很难界定，不同的人会有不同的背景，带来的标准也不同，更何况不同的应用背景对其也有很大的影响。有些应用如普通队列，一项一项就可以，有些则需要完全载入，如树形结构。而不同的人也会有很大的不同，对某个知识的形式化可能让刚接触的人不能快速载入，而当熟练掌握后，形式化的简练也可以方便更快的载入，譬如文本文件和二进制载入的区别。合适，永远都是一个重要的主题。 

迷惘，同样会造成焦虑，因为迷惘也会造成逻辑的复杂化，迷惘，不过是面对不明朗的情况。那么往往对真实的情况会有很多种可能性，这就又掉入了混沌理论里，我们可控的往往都是受限的，没人能够控制这样的一个世界。多可能性带来的就是一个巨大无边的决策树，就像逻辑分支更多一样，可是，这里的未知太多，连序列化存储下来的可能性都没有，更无法在大脑的范围内来处理了。面对这样的情况，只有一个途径，就是简化。但是简化的方法却又很多，可以简化未知量，去掉影响因子较小的，可以估算范围，关注自己能力范围内的，可以演化一下再剪枝的。但是，尝试获得全局最优解的可能性是不存在的，能做的可能只是在可见范围内找到一个相对的最优解，可是，"可见范围"却是一个无法准确定义的东西，而"最优解"更是存在一个评价标准的问题。我们往往对自己的"可见范围"有太多的自信，譬如，计划，多少计划真的能够完整实现呢？当不能按照原计划执行的时候，往往就说明了存在自己计划时未考虑的不确定因素，而且这个因素的影响力也达到一个级别。所以，需要控制不确定因素才能保证计划的执行能够进一步，但是不确定因素太多，人类能力却又太小，能够做到的往往就是那么几个不确定因素的控制，比如，标准的作息规律，其实，这也未必真的能够被自己控制。这也譬如系统的稳定性，与外部的接口越多，往往稳定性就越低下，这里的外部相对的内部也是一个可变的定义，可以是一个人、可以是一个家庭、甚至是可以自己的整个社交网络，只要能够将这一个范围纳入自己的控制范围，但是，这种强调控制欲的方法，往往会让人乐在其中而忽略了更大范围内的无法控制的因素。而控制范围扩大本身的影响更是会加剧其他因素的变化和不确定性，单纯的简单模型在现实中能否能够实现准确的预测永远是一个疑问，往往计划需要的就是准确的预测，而不是概率预测。如果按照概率预测，那么就重新掉入了多种可能性的问题中。即使1%的发生概率，考虑其存在后，之后的整个考虑也会由于这一可能性扩大化。更何况，"最优解"的确定更是一个问题，因为不确定造成了评价因素的不确定，可能某一个很好的工作是"最优解"，但是从全局上看，可能由于技术或者政治的发展，该工作很快就消失，这一可能性在20年左右的跨度内是存在的，而20年前对这一工作的存在是否的预测，目前来看也是很难的。那么造成的一个结果就是"最优解"不能过于具体，而应该抽象成为，较高的社会地位、良好的收入等等，但是一旦抽象如此，计划的目标就变得模糊不清而不具备指导意义了。 

历史数据的存在，给我们提供了一个很好的机会用来预测，或者准确的说是猜测。机器学习就是一个依据概率和数据的猜测方法。猜测的成功率，依赖于历史数据的准确和整体趋势的稳定性。历史数据中噪音数据的去除也是一个概率问题。而整体趋势的稳定性，本身也是基于历史数据给出的，谁也不能完全确定这一稳定性在未来是否能够保持下去，当然，如果我们能够进入更底层，确定这些稳定性的影响因素，再确定这些影响因素，就可以很好确定稳定性，但是底层的影响因素或许有更底层的因素，底层的因素或许也是一个概率因素。何况，进入底层的代价到底有多高，也是不确定的。 

譬如科学研究对于不可控因素的隔离、简化，保证了在某一层面上的精确性。而在社会研究中，往往难以隔离不可控因素，或者药物研究在实体上的试验，这些提供的结果往往更加依赖于概率，通过大量样本试图将噪音和不确定因素平均和消除，但是这个原生的原因，带来的是对个体的指导最后还是要回归到"具体问题具体分析"。譬如心理学应该就具备这样的特点。
