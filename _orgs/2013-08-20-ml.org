#+BEGIN_HTML
---
layout: post
title: Machine Learning课程
---
#+END_HTML
* 说明
  之前在Coursera上选了个ML的课程，毕竟工作上也要用到，上门课程也好歹算得上准科班了，而且么，作业用matlab做的，正好自己之前就打算学，不过MIT的那个MATLAB的教程自己的笔记一直停在第二课上...这个直接动手的。虽说课程上用的是octave，不过么，我在matlab上也都跑过，没什么问题。
  
  课程本身难度不算大的，最近成绩出来，自己在学校里面90+的课程还是不算多的，所以这门课难度，起码比学校里面大多数的课程简单。当然，是本身难度不大了，你要是每个课程的内容都深入，来一堆扩展资料和论文，那就算了吧，这个世界把一个东西弄大还是很容易的，一个不小心，大怪兽就出现了。

  当然，难度大的版本是有的，stanford自己网站上的这么课程难度就要大一些，当然，为了照顾我等智障儿童一类的弱势群体以及贯彻多赞扬少批评的基本教育方针，大家都会说，那边的内容要“偏学术”一点。:-)，好吧，我承认，以后我要是说自己不适合搞学术其实就是老子智商不够的委婉说法。话说回来了，什么时候linux下输入法这么智能了，打个呵呵竟然还出的笑脸，o(∩∩)o...哈哈，^_^ ，看着这么像搜狗的词库尼...

* 全貌
  入门类的课程，都是介绍广泛，深入较少。这个课程也这样，线性回归->逻辑回归->神经网络->SVM->聚类->推荐系统，这算是算法路线了，中间夹杂的Regularization->Bias/Variance->对数据的分析方法->降维->Anomaly Detection的方法路线了。
  
  算法方面，介绍了基本原理，简单的算法是自己用matlab写，复杂的就提前帮你弄好了，主要也就是SVM不用自己写，因为，自己写你还指望这门课能这么快接客么，结课，烂输入法。否则还得看不少优化方面的东西。有关SVM，看pluskid的SVM系列就挺不错的了。其他的论文，不是搞学术的，就不用看了。非论文的资料，其他的我基本持反对意见了，没有比pluskid写的更好的了。这里就忍不住吐槽《统计学习方法》这本书了，纯属低不成高不就的鸡肋，唯一存在的意义就是每章后面的那堆论文列表了，后面的习题没注意过，内容基本就是公式堆出来的，没有原理性的说明，举例上也不怎么感冒。搞学术的吧，内容没用处，搞工程的吧，内容用不上。估计给数学系转ML的看比较合适。当然，这只是对书的评价。与其买这个，不如买本国外的大部头看看，相对会有更多思想性的东西。
  
  貌似有个blog有一个ML的笔记，11年，应该是参考的斯坦福自己网站的内容，下了资料就把人家网站地址给忘记了....从小妈妈对我说，吃水不忘挖井人。
  
  方法方面，主要集中在learning curve上，通过分析这个来推断拟合情况，然后再定算法的参数。方法上基本都是这个思想，利用验证集来定参数。

* 课程内容
  具体内容么，我没做笔记......这是最对不起江东父老的，下次上课的时候注意。这门课不像之前的Programming Language，课程里面的materials基本覆盖ppt和视频，所以那门课学完了我都不知道老师长什么样子。因为看视频其实效率很低的么，ML的视频我也都是调1.25-2的速度看。

  作业因为有pdf指导，所以都是按照上面的指导一步步的来的。基本也没有什么太大的阻碍，唯一比较麻烦的是实现神经网络的后向算法，这个都打算不做了，没想到最后碰上延后作业提交的deadline，想了想，也就完成了。后来一看算分方法，要去掉一个最低分的，立马觉得亏大发了......我发现，我不仅没笔记，我连每课的代码都没有保存...下次我态度一定要认真点，不能这样了。octave写这些内容确实合适，方便太多了，课程的作业基本没有超过80行的，这还包括自己无聊的空行和蛋疼的注释，以上对matlab也一样，同样的代码，两个平台都是可以运行的。

* 后续
  1. 我重新整理下课程资料。
  2. 完整看一遍挖井人的笔记，原来是为了看下EM算法才下的他的资料。
