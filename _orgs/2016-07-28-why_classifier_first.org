#+BEGIN_HTML
---
layout: post
title: 为什么需要分类器作为预训练
---
#+END_HTML

现在CNN的各种任务的训练，往往都会以分类模型作为基础进行finetune。那么，这一过程是否是必须的呢？

起码在我看来，这一过程是不可避免的，或者说，只要CNN进行其它复杂任务，都必须先学习分类模型。
* 人类的认知过程
  人类的学习过程是什么样子的？我们可以看到，都是首先学习概念。让人类可以回答：这是什么？
  
  其实，这一过程就是人类学习分类的过程。概念，不过是一个类别。我们能够区分概念，就是因为我们成功的掌握了一个具有我们接触的所有概念的分类器。无论是从小父母的教育，还是我们在学校中接触到的系统的教育。整个过程都是以概念学习为起点的，或者说是，我们的教育都开始于训练分类器。

  我们可以很容易的回忆出来，或者观察到，父母对初生子女的教育，“这是XX”。或者：叫爸爸，叫妈妈，爸爸，妈妈。这一类的口头禅。这和我们训练分类模型的手段简直一模一样。只是换成了我们举着一张图片，然后对着机器说，“这是狗”，“这是猫”。

* 分类＝概念学习
  人类概念学习与机器的分类学习有异曲同工的地方。甚至是教学方法都是类似的，当然，我们不知道人类大脑具体的形成概念的方法，可是，我们却可以知道CNN是如何将概念保存在整个模型中的。相关的很多论文都关注可视化CNN网络内部，探索每个神经元对特别类别的激活情况，或者反向将激活情况传播到输入，还有DeepDream等等。

  其实我们在阅读这类论文的过程中知道，CNN成功的学习到了不同概念具有的特征，其实人类也是利用不同概念具有的特征来实现概念的区分的。CNN可以学习不同的颜色、边缘信息、形状，最终形成一个模糊的形状，在CNN预测的过程中，只是将这些模糊的形状与输入进行匹配，然后根据接近的情况排序。

  模式匹配然后打分，这似乎与人类的预测过程不一样，但是，如果我们作为人类，遇到了一个非常接近两个概念的事物，也会出现迷惑的情况，这类似SVM分类在超平面边界附近时候的情况，或者是CNN获得了几个概率非常接近的预测结果。因此，我们人类也会遇到这种情况，而且如果我们亲自遇到了这样的情况，就会有亲身体会，我们与CNN，没有什么不同。
  

  另外有论文希望通过逆向工程来欺骗CNN，让CNN出现十分低级的错误。但我相信，人类也是如此，平时生活中我们就会出现低级错误。而且，我相信，一旦我们能够更好的理解人类大脑，同样可以通过逆向工程让人类出现十分低级的错误。何况，在心理学和视觉这块，人类的科学家已经具有能力欺骗人类大脑。
* 更加复杂的任务：决策
  NN可以很好的学习到各种概念，从我的理解来看，对于大部分的概念区分的任务(或者说分类任务)，NN的能力将会不亚于人类。或许目前很多领域的分类任务没有达到人类水平，但是我认为这只是NN的训练者本身没有找到适合电脑学习这些领域的概念的方式。
  
  这让我考虑到了思考快与慢中的问题，低级脑和高级脑。我们可以看到低级脑的处理方式就是简单的模式匹配，并且迅速做出反应，这与NN的模式匹配可以说是一模一样。而高级脑的功能则是进行复杂的逻辑推理与演算，这不得不让人想起人工智能中的符号方法。

  那么，按照我的想法，
  1. 低级脑的功能，NN可以做到非常好的模拟，并且获得不亚于人类的性能。所以，在未来的一段时间里，人类一部分低级脑的功能会移交给NN这一类的模式匹配。
  2. 高级脑的功能，目前这种单纯的模式匹配无法做到。当然，符号方法肯定也没法做到。但通过一些专用的模型结构，应该可以学习到某个领域内高级脑的部分功能。
  3. 人类的创新能力，目前的方法100%无法实现。或许可以增加模型运行中的随机化可以带来创新，随机的建立NN链接和神经元等。不过这只会变成科幻小说。


* 总结
  通篇的废话只是说明我的如下观点：
  1. NN依然只是简单的模式匹配方法。[fn:1]
  2. 人类的低级脑的活动也是模式匹配。
  3. NN具有替代人类低级脑的潜力，并且做到不亚于低级脑的性能。
  4. 高级脑的能力，NN依然望尘莫及。

* Footnotes

[fn:1] 混用了CNN与NN，但是两者本质上没有不同。

